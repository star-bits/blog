# Stable Diffusion

- [Stable Diffusion overview](https://stable-diffusion-art.com/how-stable-diffusion-work/)
- Papers: [Diffusion](https://arxiv.org/abs/2006.11239), [Stable Diffusion](https://arxiv.org/abs/2112.10752), [ControlNet](https://arxiv.org/abs/2302.05543), [IP-Adapter](https://arxiv.org/abs/2308.06721)

## Denoising in Latent Space

The model is a noise predictor. The dataset consists of image and noisy image pairs, and we teach the noise predictor to tell us how much noise is added. After the noise predictor predicts the noise, (new latent image) = (old latent image) - (predicted noise). This is repeated for each sampling step, which is normally between 20 and 100. This occurs in the latent space, not the pixel space. An image in pixel space (3, 512, 512) is converted into latent space (4, 64, 64) by the Encoder and, after going through the denoising process, is converted back to pixel space by the Decoder. The latent representation significantly reduces the computational load, making it 48 times smaller. The model uses a U-Net architecture and is fine-tuned on 512x512 pixel images in Stable Diffusion v1. Generating images larger than 512x512 may result in duplicate objects. The SDXL model defaults to 1024x1024 pixels.

## Conditioning: Text-prompt, LoRA, ControlNet, IP-Adapter

Text-prompt steers the noise predictor. Text-prompt -> Tokenizer -> Embedding -> Text Transformer -> Noise predictor. Output of the Transformer (K and V) is fed into multiple stages of the U-Net, through a cross-attention mechanism. The Transformer provides a mechanism for including different conditioning modalities. LoRA (Low-Rank Adaptation) weights modify the models's cross-attention weights. It reduces the file size by representing (m, n) matrix as a multiplication of (m, x) matrix and (x, n) matrix. ControlNet conditions the noise predictor using detected edge, human pose, depth, etc. It works by adding trainable copy of model blocks to the original model.

![스크린샷 2023-10-20 140309](https://github.com/star-bits/blog/assets/93939472/cb1ecaae-254a-48f9-9b19-d0c0bd30460f)

In the image-to-image transformation, completely random latent noise is replaced with a noise-augmented latent representation generated by an Encoder. The level of noise introduced is regulated by the denoising strength parameter. When the denoising strength is set to 1, the operation effectively becomes a text-to-image transformation. Inpainting serves as a specific subset of the image-to-image process.
